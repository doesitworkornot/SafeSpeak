{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T10:14:09.325430Z",
     "iopub.status.busy": "2024-11-23T10:14:09.324502Z",
     "iopub.status.idle": "2024-11-23T10:14:14.098690Z",
     "shell.execute_reply": "2024-11-23T10:14:14.097827Z",
     "shell.execute_reply.started": "2024-11-23T10:14:09.325395Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SSL_Anti-spoofing'...\n",
      "remote: Enumerating objects: 1579, done.\u001b[K\n",
      "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
      "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
      "remote: Total 1579 (delta 52), reused 82 (delta 48), pack-reused 1489 (from 1)\u001b[K\n",
      "Receiving objects: 100% (1579/1579), 30.57 MiB | 20.00 MiB/s, done.\n",
      "Resolving deltas: 100% (293/293), done.\n"
     ]
    }
   ],
   "source": [
    "import git\n",
    "!git clone https://github.com/TakHemlata/SSL_Anti-spoofing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T10:14:18.447513Z",
     "iopub.status.busy": "2024-11-23T10:14:18.447161Z",
     "iopub.status.idle": "2024-11-23T10:14:18.456271Z",
     "shell.execute_reply": "2024-11-23T10:14:18.455455Z",
     "shell.execute_reply.started": "2024-11-23T10:14:18.447481Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files and folders moved from /kaggle/working/SSL_Anti-spoofing to /kaggle/working/\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Specify the source directory (where files/folders are located)\n",
    "source_dir = '/kaggle/working/SSL_Anti-spoofing'\n",
    "# Specify the destination directory (where you want to move the files/folders)\n",
    "destination_dir = \"/kaggle/working/\"\n",
    "\n",
    "# Ensure destination directory exists\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Loop through all files and folders in the source directory\n",
    "for item_name in os.listdir(source_dir):\n",
    "    # Get full path of the source and destination\n",
    "    source_item = os.path.join(source_dir, item_name)\n",
    "    destination_item = os.path.join(destination_dir, item_name)\n",
    "    \n",
    "    # Move each item\n",
    "    shutil.move(source_item, destination_item)\n",
    "\n",
    "print(f\"All files and folders moved from {source_dir} to {destination_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T10:14:22.790897Z",
     "iopub.status.busy": "2024-11-23T10:14:22.790177Z",
     "iopub.status.idle": "2024-11-23T10:14:22.796321Z",
     "shell.execute_reply": "2024-11-23T10:14:22.795310Z",
     "shell.execute_reply.started": "2024-11-23T10:14:22.790863Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /kaggle/working/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1/fairseq/data/indexed_dataset.py deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/kaggle/working/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1/fairseq/data/indexed_dataset.py\"\n",
    "\n",
    "# Delete the file\n",
    "try:\n",
    "    os.remove(file_path)\n",
    "    print(f\"File {file_path} deleted successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file {file_path} does not exist.\")\n",
    "except PermissionError:\n",
    "    print(\"You do not have permission to delete this file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T10:14:33.745341Z",
     "iopub.status.busy": "2024-11-23T10:14:33.744450Z",
     "iopub.status.idle": "2024-11-23T10:14:33.764896Z",
     "shell.execute_reply": "2024-11-23T10:14:33.764179Z",
     "shell.execute_reply.started": "2024-11-23T10:14:33.745306Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied /kaggle/input/float32/indexed_dataset.py to /kaggle/working/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1/fairseq/data/indexed_dataset.py\n"
     ]
    }
   ],
   "source": [
    "source_path = \"/kaggle/input/float32/indexed_dataset.py\"\n",
    "destination_path = \"/kaggle/working/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1/fairseq/data/indexed_dataset.py\"\n",
    "\n",
    "# Copy the file\n",
    "shutil.copy2(source_path, destination_path)\n",
    "\n",
    "print(f\"Copied {source_path} to {destination_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T10:14:48.006565Z",
     "iopub.status.busy": "2024-11-23T10:14:48.005852Z",
     "iopub.status.idle": "2024-11-23T10:15:35.124059Z",
     "shell.execute_reply": "2024-11-23T10:15:35.123013Z",
     "shell.execute_reply.started": "2024-11-23T10:14:48.006510Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///kaggle/working/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+4acaa61) (1.16.0)\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+4acaa61) (3.0.10)\n",
      "Collecting hydra-core<1.1,>=1.0.7 (from fairseq==1.0.0a0+4acaa61)\n",
      "  Downloading hydra_core-1.0.7-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting omegaconf<2.1 (from fairseq==1.0.0a0+4acaa61)\n",
      "  Downloading omegaconf-2.0.6-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+4acaa61) (1.26.4)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+4acaa61) (2024.5.15)\n",
      "Collecting sacrebleu>=1.4.12 (from fairseq==1.0.0a0+4acaa61)\n",
      "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+4acaa61) (2.4.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+4acaa61) (4.66.4)\n",
      "Collecting bitarray (from fairseq==1.0.0a0+4acaa61)\n",
      "  Downloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: torchaudio>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+4acaa61) (2.4.0)\n",
      "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+4acaa61)\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq==1.0.0a0+4acaa61) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq==1.0.0a0+4acaa61) (4.12.2)\n",
      "Collecting portalocker (from sacrebleu>=1.4.12->fairseq==1.0.0a0+4acaa61)\n",
      "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+4acaa61) (0.9.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+4acaa61) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+4acaa61) (5.3.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->fairseq==1.0.0a0+4acaa61) (2.22)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0+4acaa61) (3.15.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0+4acaa61) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0+4acaa61) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0+4acaa61) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0+4acaa61) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->fairseq==1.0.0a0+4acaa61) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->fairseq==1.0.0a0+4acaa61) (1.3.0)\n",
      "Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
      "Downloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.3/278.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
      "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
      "  Building editable for fairseq (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairseq: filename=fairseq-1.0.0a0+4acaa61-0.editable-cp310-cp310-linux_x86_64.whl size=9403 sha256=86ac98d2fea32a57b52b626ab37a6a5d2f1476adb4984033a3a881dbeeb6bfb2\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vmr79oft/wheels/35/08/f6/d9fd34bf105b76f5aa33c01c514418ef0f846fcd6bc17c20ee\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=d2059910b3f9d31154dc62e7937160fbb3bcc71a8e599f4934463675a3ad7c54\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
      "Successfully built fairseq antlr4-python3-runtime\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, sacrebleu, hydra-core, fairseq\n",
      "Successfully installed antlr4-python3-runtime-4.8 bitarray-3.0.0 fairseq-1.0.0a0+4acaa61 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-3.0.0 sacrebleu-2.4.3\n"
     ]
    }
   ],
   "source": [
    "!cd fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1 && pip install --editable ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T10:15:40.443478Z",
     "iopub.status.busy": "2024-11-23T10:15:40.443116Z",
     "iopub.status.idle": "2024-11-23T10:15:49.693827Z",
     "shell.execute_reply": "2024-11-23T10:15:49.692947Z",
     "shell.execute_reply.started": "2024-11-23T10:15:40.443447Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa==0.9.1 (from -r requirements.txt (line 2))\n",
      "  Downloading librosa-0.9.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting tensorboardX==2.5 (from -r requirements.txt (line 3))\n",
      "  Downloading tensorboardX-2.5-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: audioread>=2.1.5 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (3.0.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (5.1.1)\n",
      "Collecting resampy>=0.2.2 (from librosa==0.9.1->-r requirements.txt (line 2))\n",
      "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numba>=0.45.1 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (1.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from tensorboardX==2.5->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from tensorboardX==2.5->-r requirements.txt (line 3)) (3.20.3)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.45.1->librosa==0.9.1->-r requirements.txt (line 2)) (0.43.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->librosa==0.9.1->-r requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 2)) (3.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.19.1->librosa==0.9.1->-r requirements.txt (line 2)) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.10.2->librosa==0.9.1->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.1->-r requirements.txt (line 2)) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 2)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 2)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 2)) (2024.8.30)\n",
      "Downloading librosa-0.9.1-py3-none-any.whl (213 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.1/213.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tensorboardX, resampy, librosa\n",
      "  Attempting uninstall: tensorboardX\n",
      "    Found existing installation: tensorboardX 2.6.2.2\n",
      "    Uninstalling tensorboardX-2.6.2.2:\n",
      "      Successfully uninstalled tensorboardX-2.6.2.2\n",
      "  Attempting uninstall: librosa\n",
      "    Found existing installation: librosa 0.10.2.post1\n",
      "    Uninstalling librosa-0.10.2.post1:\n",
      "      Successfully uninstalled librosa-0.10.2.post1\n",
      "Successfully installed librosa-0.9.1 resampy-0.4.3 tensorboardX-2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T10:15:56.373846Z",
     "iopub.status.busy": "2024-11-23T10:15:56.373057Z",
     "iopub.status.idle": "2024-11-23T10:16:26.933812Z",
     "shell.execute_reply": "2024-11-23T10:16:26.933138Z",
     "shell.execute_reply.started": "2024-11-23T10:15:56.373807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/working/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1')\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "from data_utils_SSL import genSpoof_list,Dataset_ASVspoof2019_train,Dataset_ASVspoof2021_eval\n",
    "from model import Model\n",
    "from tensorboardX import SummaryWriter\n",
    "from core_scripts.startup_config import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T10:16:41.501869Z",
     "iopub.status.busy": "2024-11-23T10:16:41.501037Z",
     "iopub.status.idle": "2024-11-23T10:16:41.574107Z",
     "shell.execute_reply": "2024-11-23T10:16:41.573081Z",
     "shell.execute_reply.started": "2024-11-23T10:16:41.501821Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.amp import GradScaler, autocast # Updated import for GradScaler\n",
    "\n",
    "# Initialize GradScaler for mixed precision on CUDA\n",
    "scaler = GradScaler(device='cuda')\n",
    "\n",
    "def evaluate_accuracy(dev_loader, model, device, max_samples=None):\n",
    "    val_loss = 0.0\n",
    "    num_total = 0\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([0.1, 0.9]).to(device))\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for batch_x, batch_y in dev_loader:\n",
    "            batch_size = batch_x.size(0)\n",
    "            \n",
    "            # Stop if max_samples limit is reached\n",
    "            if max_samples and num_total + batch_size > max_samples:\n",
    "                batch_size = int(max_samples - num_total)  # Convert to integer to meet slicing requirement\n",
    "                batch_x = batch_x[:batch_size]\n",
    "                batch_y = batch_y[:batch_size]\n",
    "            \n",
    "            num_total += batch_size\n",
    "            \n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.view(-1).type(torch.int64).to(device)\n",
    "            \n",
    "            batch_out = model(batch_x)\n",
    "            batch_loss = criterion(batch_out, batch_y)\n",
    "            \n",
    "            val_loss += (batch_loss.item() * batch_size)\n",
    "            \n",
    "            if max_samples and num_total >= max_samples:\n",
    "                break  # Stop processing further batches once max_samples is reached\n",
    "    \n",
    "    val_loss /= num_total\n",
    "    return val_loss\n",
    "\n",
    "def train_epoch(train_loader, model, optimizer, device):\n",
    "    running_loss = 0.0\n",
    "    num_total = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([0.1, 0.9]).to(device))\n",
    "    \n",
    "    # Use tqdm for tracking batch progress within each epoch\n",
    "    batch_iterator = tqdm(train_loader, desc=\"Training\", leave=True)\n",
    "    for batch_x, batch_y in batch_iterator:\n",
    "        batch_size = batch_x.size(0)\n",
    "        num_total += batch_size\n",
    "        \n",
    "        batch_x = batch_x.to(device, non_blocking=True)\n",
    "        batch_y = batch_y.view(-1).type(torch.int64).to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast('cuda'):  # Mixed precision for faster training\n",
    "            batch_out = model(batch_x)\n",
    "            batch_loss = criterion(batch_out, batch_y)\n",
    "        \n",
    "        # Backward pass with mixed precision\n",
    "        scaler.scale(batch_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        running_loss += (batch_loss.item() * batch_size)\n",
    "        \n",
    "        # Update tqdm description with batch loss\n",
    "        batch_iterator.set_description(f\"Training - Batch Loss: {batch_loss.item():.4f}\")\n",
    "        \n",
    "    running_loss /= num_total\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T10:16:43.537968Z",
     "iopub.status.busy": "2024-11-23T10:16:43.537122Z",
     "iopub.status.idle": "2024-11-23T10:16:43.544415Z",
     "shell.execute_reply": "2024-11-23T10:16:43.543449Z",
     "shell.execute_reply.started": "2024-11-23T10:16:43.537934Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define args dictionary with hardcoded values\n",
    "args = {\n",
    "    'batch_size': 16,\n",
    "    'num_epochs': 3,\n",
    "    'lr': 0.000001,\n",
    "    'weight_decay': 0.0001,\n",
    "    'loss': 'weighted_CCE',\n",
    "    'seed': 1234,  # Random seed for reproducibility\n",
    "    'model_path': None,  # Path to a model checkpoint\n",
    "    'comment': None,  # Description for the saved model\n",
    "    'track': 'LA',  # Dataset track; options are 'LA', 'PA', 'DF'\n",
    "    'eval_output': None,  # Path to save evaluation results\n",
    "    'eval': False,  # Boolean for evaluation mode\n",
    "    'is_eval': False,  # Boolean for evaluation dataset\n",
    "    'eval_part': 0,  # Part of evaluation to process\n",
    "    'cudnn_deterministic_toggle': False,  # Use deterministic CuDNN behavior\n",
    "    'cudnn_benchmark_toggle': True,  # Use CuDNN benchmark for faster runtime\n",
    "    \n",
    "    # RawBoost data augmentation options\n",
    "    'algo': 4,  # RawBoost algorithm selection\n",
    "\n",
    "    # LnL_convolutive_noise parameters\n",
    "    'nBands': 5,  # Number of notch filters\n",
    "    'minF': 20,  # Minimum center frequency of notch filter\n",
    "    'maxF': 8000,  # Maximum center frequency of notch filter\n",
    "    'minBW': 100,  # Minimum bandwidth of filter\n",
    "    'maxBW': 1000,  # Maximum bandwidth of filter\n",
    "    'minCoeff': 10,  # Minimum filter coefficients\n",
    "    'maxCoeff': 100,  # Maximum filter coefficients\n",
    "    'minG': 0,  # Minimum gain factor of linear component\n",
    "    'maxG': 0,  # Maximum gain factor of linear component\n",
    "    'minBiasLinNonLin': 5,  # Minimum gain difference between linear/non-linear components\n",
    "    'maxBiasLinNonLin': 20,  # Maximum gain difference between linear/non-linear components\n",
    "    'N_f': 5,  # Order of non-linearity (1 means only linear)\n",
    "\n",
    "    # ISD_additive_noise parameters\n",
    "    'P': 10,  # Max number of uniformly distributed samples in [%]\n",
    "    'g_sd': 2,  # Gain parameter for additive noise\n",
    "\n",
    "    # SSI_additive_noise parameters\n",
    "    'SNRmin': 10,  # Minimum SNR for colored noise\n",
    "    'SNRmax': 40  # Maximum SNR for colored noise\n",
    "}\n",
    "\n",
    "from types import SimpleNamespace\n",
    "args = SimpleNamespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T10:16:47.279245Z",
     "iopub.status.busy": "2024-11-23T10:16:47.278578Z",
     "iopub.status.idle": "2024-11-23T10:16:47.289014Z",
     "shell.execute_reply": "2024-11-23T10:16:47.288123Z",
     "shell.execute_reply.started": "2024-11-23T10:16:47.279211Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudnn_deterministic set to False\n",
      "cudnn_benchmark set to True\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "set_random_seed(args.seed, args)\n",
    "track = args.track\n",
    "assert track in ['LA', 'PA','DF'], 'Invalid track given'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T10:16:59.957206Z",
     "iopub.status.busy": "2024-11-23T10:16:59.956904Z",
     "iopub.status.idle": "2024-11-23T10:16:59.976359Z",
     "shell.execute_reply": "2024-11-23T10:16:59.975559Z",
     "shell.execute_reply.started": "2024-11-23T10:16:59.957181Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import fairseq\n",
    "\n",
    "class SSLModel(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(SSLModel, self).__init__()\n",
    "        \n",
    "        cp_path = '/kaggle/input/xlsr2-300m/xlsr2_300m.pt'   # Path to pre-trained model \n",
    "        model, cfg, task = fairseq.checkpoint_utils.load_model_ensemble_and_task([cp_path])\n",
    "        self.model = model[0].to(device)  # Move the model to the specified device only once\n",
    "        self.device = device\n",
    "        self.out_dim = 1024\n",
    "\n",
    "    def extract_feat(self, input_data):\n",
    "        # Ensure input is on the correct device\n",
    "        input_data = input_data.to(self.device)\n",
    "\n",
    "        # Adjust input shape to (batch, length) if necessary\n",
    "        input_tmp = input_data[:, :, 0] if input_data.ndim == 3 else input_data\n",
    "                \n",
    "        # Extract features [batch, length, dim]\n",
    "        emb = self.model(input_tmp, mask=False, features_only=True)['x']\n",
    "        return emb\n",
    "\n",
    "\n",
    "class PSFAN_Backend(nn.Module):\n",
    "    def __init__(self, input_channels=128, num_classes=2):\n",
    "        super(PSFAN_Backend, self).__init__()\n",
    "        \n",
    "        # First convolutional block with dilation rate = 1\n",
    "        self.conv1 = nn.Conv1d(input_channels, 128, kernel_size=3, dilation=1, padding=1)\n",
    "        self.conv1x1_1 = nn.Conv1d(128, 128, kernel_size=1)\n",
    "        self.conv3x3_1 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv1x1_2 = nn.Conv1d(128, 128, kernel_size=1)\n",
    "        self.attention1 = nn.Sigmoid()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Second convolutional block with dilation rate = 2\n",
    "        self.conv2 = nn.Conv1d(128, 128, kernel_size=3, dilation=2, padding=2)\n",
    "        self.conv1x1_3 = nn.Conv1d(128, 128, kernel_size=1)\n",
    "        self.conv3x3_2 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv1x1_4 = nn.Conv1d(128, 128, kernel_size=1)\n",
    "        self.attention2 = nn.Sigmoid()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Third convolutional block with dilation rate = 3\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, dilation=3, padding=3)\n",
    "        self.conv1x1_5 = nn.Conv1d(256, 256, kernel_size=1)\n",
    "        self.conv3x3_3 = nn.Conv1d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv1x1_6 = nn.Conv1d(256, 256, kernel_size=1)\n",
    "        self.attention3 = nn.Sigmoid()\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Fourth convolutional block with dilation rate = 4\n",
    "        self.conv4 = nn.Conv1d(256, 256, kernel_size=3, dilation=4, padding=4)\n",
    "        self.conv1x1_7 = nn.Conv1d(256, 256, kernel_size=1)\n",
    "        self.conv3x3_4 = nn.Conv1d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv1x1_8 = nn.Conv1d(256, 256, kernel_size=1)\n",
    "        self.attention4 = nn.Sigmoid()\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Global Average Pooling layer for each block output\n",
    "        self.gap1 = nn.AdaptiveAvgPool1d(1)\n",
    "        self.gap2 = nn.AdaptiveAvgPool1d(1)\n",
    "        self.gap3 = nn.AdaptiveAvgPool1d(1)\n",
    "        self.gap4 = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc_concat = nn.Linear(128 + 128 + 256 + 256, 16)  # Concatenated GAP output to dense layer\n",
    "        self.fc_out = nn.Linear(16, num_classes)  # Final output layer\n",
    "        \n",
    "        self.activation = nn.LeakyReLU(0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First convolutional block with attention and pooling\n",
    "        x1 = self.conv1(x)\n",
    "        x1_attention = self.attention1(self.conv1x1_1(self.conv3x3_1(self.conv1x1_2(x1))))\n",
    "        x1 = x1_attention * x1\n",
    "        x1 = self.pool1(x1)\n",
    "        x1_gap = self.gap1(x1).squeeze(-1)  # Apply GAP and remove last dimension to (batch, channels)\n",
    "\n",
    "        # Second convolutional block with attention and pooling\n",
    "        x2 = self.conv2(x1)\n",
    "        x2_attention = self.attention2(self.conv1x1_3(self.conv3x3_2(self.conv1x1_4(x2))))\n",
    "        x2 = x2_attention * x2\n",
    "        x2 = self.pool2(x2)\n",
    "        x2_gap = self.gap2(x2).squeeze(-1)\n",
    "\n",
    "        # Third convolutional block with attention and pooling\n",
    "        x3 = self.conv3(x2)\n",
    "        x3_attention = self.attention3(self.conv1x1_5(self.conv3x3_3(self.conv1x1_6(x3))))\n",
    "        x3 = x3_attention * x3\n",
    "        x3 = self.pool3(x3)\n",
    "        x3_gap = self.gap3(x3).squeeze(-1)\n",
    "\n",
    "        # Fourth convolutional block with attention and pooling\n",
    "        x4 = self.conv4(x3)\n",
    "        x4_attention = self.attention4(self.conv1x1_7(self.conv3x3_4(self.conv1x1_8(x4))))\n",
    "        x4 = x4_attention * x4\n",
    "        x4 = self.pool4(x4)\n",
    "        x4_gap = self.gap4(x4).squeeze(-1)\n",
    "\n",
    "        # Concatenate the GAP outputs\n",
    "        x_concat = torch.cat([x1_gap, x2_gap, x3_gap, x4_gap], dim=1)  # Shape: (batch, 768)\n",
    "\n",
    "        # Fully connected layers for classification\n",
    "        x = self.activation(self.fc_concat(x_concat))  # Dense layer with 16 units\n",
    "        output = self.fc_out(x)  # Output layer with 2 units\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, args, device):\n",
    "        super(Model, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        # wav2vec 2.0 front-end remains unchanged\n",
    "        self.ssl_model = SSLModel(self.device)\n",
    "        self.LL = nn.Linear(self.ssl_model.out_dim, 128).to(device)  # Reduces dimensionality to 128 for compatibility\n",
    "\n",
    "        # PSFAN backend with Conv1D for multi-scale feature extraction\n",
    "        self.backend = PSFAN_Backend(input_channels=128, num_classes=2).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Move input to the same device as model\n",
    "        x = x.to(self.device)\n",
    "\n",
    "        # wav2vec 2.0 feature extraction\n",
    "        x_ssl_feat = self.ssl_model.extract_feat(x)\n",
    "        x = self.LL(x_ssl_feat)  # Dimensionality reduction to 128 channels\n",
    "        x = x.transpose(1, 2)  # Reshape to (batch, features, timesteps) for Conv1D format\n",
    "        \n",
    "        # Backend processing for classification\n",
    "        output = self.backend(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T10:17:05.769580Z",
     "iopub.status.busy": "2024-11-23T10:17:05.768755Z",
     "iopub.status.idle": "2024-11-23T10:17:37.753228Z",
     "shell.execute_reply": "2024-11-23T10:17:37.752366Z",
     "shell.execute_reply.started": "2024-11-23T10:17:05.769545Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1/fairseq/checkpoint_utils.py:313: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(f, map_location=torch.device(\"cpu\"))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_params: 318749618\n"
     ]
    }
   ],
   "source": [
    "model_tag = 'model_{}_{}_{}_{}_{}'.format(\n",
    "    track, args.loss, args.num_epochs, args.batch_size, args.lr)\n",
    "if args.comment:\n",
    "    model_tag = model_tag + '_{}'.format(args.comment)\n",
    "model_save_path = os.path.join('models', model_tag)\n",
    "\n",
    "#set model save directory\n",
    "if not os.path.exists(model_save_path):\n",
    "    os.mkdir(model_save_path)\n",
    "\n",
    "#GPU device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'                  \n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "model = Model(args,device)\n",
    "nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
    "model =model.to(device)\n",
    "print('nb_params:',nb_params)\n",
    "\n",
    "#set Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr,weight_decay=args.weight_decay)\n",
    "\n",
    "if args.model_path:\n",
    "    model.load_state_dict(torch.load(args.model_path,map_location=device))\n",
    "    print('Model loaded : {}'.format(args.model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T10:17:45.085790Z",
     "iopub.status.busy": "2024-11-23T10:17:45.085008Z",
     "iopub.status.idle": "2024-11-23T10:18:17.538195Z",
     "shell.execute_reply": "2024-11-23T10:18:17.537231Z",
     "shell.execute_reply.started": "2024-11-23T10:17:45.085757Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "nb_params: 318749618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/3874279850.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated model weights loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "model_path1 = '/kaggle/input/fed1-dev-and-train/fed1/epoch_2 (1).pth' # Path to model weights from client 1\n",
    "model_path2 = '/kaggle/input/fed1-dev-and-train/fed1/epoch_2.pth'  # Path to model weights from client 2\n",
    "model_path3 = '/kaggle/input/fed1-test/epoch_1.pth' # Path to model weights from client 3\n",
    "\n",
    "# Model tag and save path setup\n",
    "model_tag = 'model_{}_{}_{}_{}_{}'.format(\n",
    "    track, args.loss, args.num_epochs, args.batch_size, args.lr)\n",
    "if args.comment:\n",
    "    model_tag = model_tag + '_{}'.format(args.comment)\n",
    "model_save_path = os.path.join('models', model_tag)\n",
    "\n",
    "# Ensure model save directory exists\n",
    "if not os.path.exists(model_save_path):\n",
    "    os.mkdir(model_save_path)\n",
    "\n",
    "# Set device to GPU if available, else CPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'                  \n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "# Initialize the model architecture (without loading weights)\n",
    "model = Model(args, device).to(device)\n",
    "nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
    "print('nb_params:', nb_params)\n",
    "\n",
    "# Function to load model weights from a given path\n",
    "def load_model_weights(path, device):\n",
    "    if os.path.exists(path):\n",
    "        return torch.load(path, map_location=device)\n",
    "    else:\n",
    "        print(f\"Warning: Model path {path} does not exist.\")\n",
    "        return None\n",
    "\n",
    "# Load weights from each client model\n",
    "state_dict1 = load_model_weights(model_path1, device)\n",
    "state_dict2 = load_model_weights(model_path2, device)\n",
    "state_dict3 = load_model_weights(model_path3, device)\n",
    "\n",
    "# Ensure all state_dicts are loaded successfully\n",
    "if state_dict1 and state_dict2 and state_dict3:\n",
    "    # Aggregate weights by averaging\n",
    "    aggregated_state_dict = {}\n",
    "    for key in state_dict1.keys():\n",
    "        # Average weights from the three clients\n",
    "        aggregated_state_dict[key] = (state_dict1[key] + state_dict2[key] + state_dict3[key]) / 3.0\n",
    "    \n",
    "    # Load the aggregated weights into the model\n",
    "    del state_dict1, state_dict2, state_dict3\n",
    "    model.load_state_dict(aggregated_state_dict)\n",
    "    del aggregated_state_dict\n",
    "    print(\"Aggregated model weights loaded successfully.\")\n",
    "else:\n",
    "    print(\"Error: Failed to load weights from all clients. Check file paths.\")\n",
    "\n",
    "# Set up the optimizer with the aggregated model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T10:18:27.344344Z",
     "iopub.status.busy": "2024-11-23T10:18:27.344004Z",
     "iopub.status.idle": "2024-11-23T10:18:27.503066Z",
     "shell.execute_reply": "2024-11-23T10:18:27.501963Z",
     "shell.execute_reply.started": "2024-11-23T10:18:27.344313Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of training trials 25380\n",
      "no. of validation trials 71237\n"
     ]
    }
   ],
   "source": [
    "if args.eval:\n",
    "    file_eval = genSpoof_list(\n",
    "        dir_meta=\"/kaggle/input/avsspoof-2021/ASVspoof2021_LA_eval/ASVspoof2021_LA_eval/ASVspoof2021.LA.cm.eval.trl.txt\",\n",
    "        is_train=False, is_eval=True)\n",
    "    print('no. of eval trials', len(file_eval))\n",
    "    eval_set = Dataset_ASVspoof2021_eval(\n",
    "        list_IDs=file_eval,\n",
    "        base_dir=\"/kaggle/input/avsspoof-2021/ASVspoof2021_LA_eval/ASVspoof2021_LA_eval/\")\n",
    "    produce_evaluation_file(eval_set, model, device, args.eval_output)\n",
    "    sys.exit(0)\n",
    "\n",
    "# Define train dataloader\n",
    "d_label_trn, file_train = genSpoof_list(\n",
    "    dir_meta=\"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\",\n",
    "    is_train=True, is_eval=False)\n",
    "print('no. of training trials', len(file_train))\n",
    "\n",
    "train_set = Dataset_ASVspoof2019_train(\n",
    "    args, list_IDs=file_train, labels=d_label_trn,\n",
    "    base_dir=\"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_train/\",\n",
    "    algo=args.algo)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=args.batch_size, num_workers=4, shuffle=True,\n",
    "    drop_last=True, pin_memory=True)  # Pin memory for faster data transfer to GPU\n",
    "\n",
    "del train_set, d_label_trn\n",
    "\n",
    "# Define validation dataloader\n",
    "d_label_dev, file_dev = genSpoof_list(\n",
    "    dir_meta=\"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\",\n",
    "    is_train=False, is_eval=False)\n",
    "print('no. of validation trials', len(file_dev))\n",
    "\n",
    "dev_set = Dataset_ASVspoof2019_train(\n",
    "    args, list_IDs=file_dev, labels=d_label_dev,\n",
    "    base_dir=\"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_eval/\",\n",
    "    algo=args.algo)\n",
    "\n",
    "dev_loader = DataLoader(\n",
    "    dev_set, batch_size=args.batch_size, num_workers=4, shuffle=False,\n",
    "    pin_memory=True)  # Pin memory for faster data transfer to GPU\n",
    "\n",
    "del dev_set, d_label_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T10:18:44.529673Z",
     "iopub.status.busy": "2024-11-23T10:18:44.529277Z",
     "iopub.status.idle": "2024-11-23T11:51:21.666152Z",
     "shell.execute_reply": "2024-11-23T11:51:21.665271Z",
     "shell.execute_reply.started": "2024-11-23T10:18:44.529640Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1586 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "Training - Batch Loss: 0.0010: 100%|██████████| 1586/1586 [26:17<00:00,  1.07it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "Training - Batch Loss: 0.0010: 100%|██████████| 1586/1586 [26:17<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 - Training Loss: 0.0113 - Validation Loss: 0.0122\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Batch Loss: 0.0012: 100%|██████████| 1586/1586 [25:42<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 - Training Loss: 0.0064 - Validation Loss: 0.0091\n",
      "Starting epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Batch Loss: 0.0040: 100%|██████████| 1586/1586 [25:44<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 - Training Loss: 0.0022 - Validation Loss: 0.0069\n"
     ]
    }
   ],
   "source": [
    "num_epochs = args.num_epochs\n",
    "writer = SummaryWriter('logs/{}'.format(model_tag))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Starting epoch {}'.format(epoch))\n",
    "    \n",
    "    # Training step\n",
    "    running_loss = train_epoch(train_loader, model, optimizer, device)\n",
    "    \n",
    "    # Validation step with error handling\n",
    "    try:\n",
    "        val_loss = evaluate_accuracy(dev_loader, model, device, max_samples=5000)\n",
    "        writer.add_scalar('val_loss', val_loss, epoch)\n",
    "        print('\\nEpoch {} - Training Loss: {:.4f} - Validation Loss: {:.4f}'.format(epoch, running_loss, val_loss))\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: An error occurred during validation at epoch {epoch}: {e}\")\n",
    "        val_loss = None  # Optionally set val_loss to None or some placeholder value\n",
    "\n",
    "    # Log training loss regardless of validation success\n",
    "    writer.add_scalar('loss', running_loss, epoch)\n",
    "    \n",
    "    # Save the model state\n",
    "    torch.save(model.state_dict(), os.path.join(model_save_path, f'epoch_{epoch}.pth'))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2286778,
     "sourceId": 3842332,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4827121,
     "sourceId": 8452149,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5952420,
     "sourceId": 9727510,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5968457,
     "sourceId": 9748923,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6056164,
     "sourceId": 9866535,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6058514,
     "sourceId": 9869755,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
